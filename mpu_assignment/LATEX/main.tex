\documentclass[a4paper,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{color}
\usepackage{geometry}
\geometry{margin=1in}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{setspace}
\usepackage{listings}
\usepackage{xcolor}  % Include xcolor for text color
\usepackage{abstract}
\usepackage{float}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{siunitx}
\usepackage{caption}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{hyperref}
\usepackage{tikz}
\usetikzlibrary{positioning}
\usepackage{tikz}
\usetikzlibrary{arrows.meta, positioning, shapes.geometric}




\title{Embedded system gesture recognition using lightweight machine learning}
\author{Nikolaos Mouzakitis}
\date{May 28, 2025}

\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegray},
    keywordstyle=\color{blue},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}

\begin{document}

\maketitle

\section{Introduction}

This project integrates an ESP32 microcontroller with an MPU9250 
inertial measurement unit (IMU) sensor to detect device movements 
and control 2 LEDs and PWM outputs accordingly. 
It implements a mechanism to persist and restore device state 
via MQTT messaging, Node-RED flow processing, and data storage in an InfluxDB time-series database.
Also Grafana is used in the last part of the project for visualization.

The key 
functionalities are:

\begin{itemize}
    \item Reading accelerometer and gyroscope Y-axis, and magmetometer X-axis data from the MPU9250.
    \item Applying threshold-based logic or machine learning to detect movement and determine LED and PWM states.
    \item Publishing device status data over MQTT.
    \item Restoring device LED and PWM states after reboot using InfluxDB queries and Node-RED.
\end{itemize}


An image of the Esp32 and the MPU sensor used in the project is presented below.
		\begin{figure}[H]
			\centering
			\includegraphics[width=0.5\textwidth]{con.jpeg}
			\caption{esp32 and mpu connected on breadboard.}
			\label{fig1:}
		\end{figure}		




\section{MPU9250 Sensor Data and Movement Detection}

\subsection{Sensor Overview}

The MPU9250 is a 9-axis IMU sensor combining a 3-axis accelerometer, 
3-axis gyroscope, and 3-axis magnetometer. 
For this project, only the accelerometer Y-axis,gyroscope Y-axis and magnetometer X-axis values 
are utilized.
\subsection{Data Acquisition}

The ESP32 reads raw sensor values for accelerometer Y (\texttt{ay}) 
,gyroscope Y (\texttt{gy}) which are used to control the activation of the two LEDs, 
and magnetometer X (\texttt{mx}) which controls the PWM, at periodic intervals.

\subsection{Threshold-Based Movement Detection}

Threshold values are defined empirically to decide when the ESP32 should 
change the states of its LEDs and PWM output.


\subsection{Controlling LEDs and PWM}

Based on movement detection, the device sets the LEDs and a common PWM variable which is applied on 
any LED that is on "active" state.

\subsection{Status Publishing}

The ESP32 publishes its current LED and PWM states 
on the MQTT topic \texttt{esp32/status} as a formatted string:

{\scriptsize
\begin{verbatim}
LED1:OFF LED2:ON PWM:15
\end{verbatim}
}
This message serves to provide the
real-time status of device outputs.

\section{MQTT Communication Architecture}

The ESP32 communicates with the Node-RED 
server via MQTT. Topics used include:

\begin{itemize}
    \item \texttt{esp32/status} — Periodic status updates including LED and PWM states.
    \item \texttt{esp32/restore\_request} — Sent by ESP32 at startup requesting last stored device state.
    \item \texttt{esp32/restore\_state} — Published by Node-RED after querying InfluxDB with the restore state data.
\end{itemize}

\subsection{Restore request and response flow}

Upon powering on, on startup, 
the ESP32 immediately publishes a \texttt{get\_latest} message 
on \texttt{esp32/restore\_request}. 
This triggers Node-RED to query the latest device state 
stored in InfluxDB and respond by publishing a 
formatted restore state message on \texttt{esp32/restore\_state}.

The ESP32 listens for this restore message and 
applies the LED and PWM settings accordingly before 
continuing normal operation.
Restoration can be observed in the following Figure, where the Esp32 
boots and assigns immidiately the latest saved state on the LEDs.

		\begin{figure}[H]
			\centering
			\includegraphics[width=0.9\textwidth]{restore.png}
			\caption{Latest state restoration as observed over UART}
			\label{fig1:}
		\end{figure}		



\section{Node-RED and InfluxDB Integration}

\subsection{Node-RED Flow Design}

Node-RED acts as the middleware for the bridging of MQTT and InfluxDB:

\begin{enumerate}
    \item \textbf{MQTT In node} listens on \texttt{esp32/restore\_request} and 
	    detects the \texttt{get\_latest} message.
    \item \textbf{InfluxDB Query node} performs a time-series query 
	    fetching the most recent LED and PWM state values.
    \item \textbf{Function node} formats the InfluxDB query response 
	    into the MQTT payload string.
    \item \textbf{MQTT Out node} publishes the 
	    formatted message on \texttt{esp32/restore\_state}.
\end{enumerate}


		\begin{figure}[H]
			\centering
			\includegraphics[width=0.9\textwidth]{node1.png}
			\caption{Node-Red data and processing flow}
			\label{fig1:}
		\end{figure}		



\subsection{InfluxDB Query}

As for the InfluxDB, version 1.6.4 has been utilized and installed
as 
{\scriptsize
\begin{verbatim} 
echo "deb https://repos.influxdata.com/ubuntu bionic stable" |  sudo tee /etc/apt/sources.list.d/influxdb.list
sudo curl -sL https://repos.influxdata.com/influxdb.key | sudo apt-key add -
sudo apt get update
sudo apt-get install -y influxdb
\end{verbatim}
}
After installation, a database is created to be used for this project.

{\scriptsize
\begin{verbatim}
influx
> create database esp32db
\end{verbatim}
}

In \texttt{function3} of the Node-Red then, when run the following 
Javascript code in order to push data in the same database.

{\scriptsize
\begin{verbatim}
let parts = msg.payload.split(" ");
let led1 = parts[0].split(":")[1] === "ON" ? 1 : 0;
let led2 = parts[1].split(":")[1] === "ON" ? 1 : 0;
let pwm = parseInt(parts[2].split(":")[1]);

msg.payload = {
    LED1: led1,
    LED2: led2,
    PWM: pwm
};
msg.measurement = "led_status";
return msg;
\end{verbatim}
}

On the InfluxDb out node in Node-Red is also specified and set
the measurement's name as "led\_status" and 
on the server configuration the
respective host ip, port number and database name as "esp32db".



The InfluxDB query used in \texttt{create\_restore\_query} node is:

{\scriptsize
\begin{verbatim}
msg.query = 'SELECT LAST("LED1"), LAST("LED2"), LAST("PWM") FROM "led_status"';
return msg;
\end{verbatim}
}
This query retrieves the most recent LED1, LED2, and PWM values stored.

In the \texttt{restore payload formating} node of Node-Red
response if formated to be given as an input on the \texttt{restore\_state} topic as:

{\scriptsize
\begin{verbatim}
let row = msg.payload[0]; // first row of result

let LED1 = row.last === 1 ? "ON" : "OFF";
let LED2 = row.last_1 === 1 ? "ON" : "OFF";
let PWM = row.last_2;

msg.payload = `LED1:${LED1} LED2:${LED2} PWM:${PWM}`;
msg.topic = "esp32/restore_state";
return msg;
\end{verbatim}
}

\subsection{State Restoration}

Upon receiving the restore payload, the ESP32 parses the string and applies the saved LED and PWM states, 
ensuring the desired recovery.


\subsection{UI visualization}

For the UI visualization 2 switches reflecting the current state of LED have been employed 
and a slider for representing the common PWM applied to them.

A new function named \texttt{function4} have been used to do the same operation as 
\texttt{function3} with the difference of returning3 outputs, one by one to be passed
on the switches and the slider.


		\begin{figure}[H]
			\centering
			\includegraphics[width=0.9\textwidth]{ui_conf.png}
			\caption{configuration show for slider of led1.}
			\label{fig1:}
		\end{figure}		

	
	A screenshot of the visualization is presented below, having the 2 switches and the slider,
	and for debug purposes the plots of the incoming data from accelerometer and gyrometer.

		\begin{figure}[H]
			\centering
			\includegraphics[width=0.9\textwidth]{ui_threshold.png}
			\caption{Node-Red UI.}
			\label{fig1:}
		\end{figure}		


\section{Summary of Data Flow}

\begin{center}
\begin{tabular}{|l|l|l|}
\hline
\textbf{Component} & \textbf{Topic / Action} & \textbf{Description} \\
\hline
ESP32 & Publish \texttt{esp32/restore\_request} & Sends \texttt{get\_latest} on startup \\
Node-RED & MQTT In on \texttt{esp32/restore\_request} & Detects restore request \\
Node-RED & InfluxDB query & Fetch last saved LED/PWM states \\
Node-RED & Function node & Format restore state payload \\
Node-RED & MQTT Out on \texttt{esp32/restore\_state} & Publishes restore state \\
ESP32 & MQTT Subscribe \texttt{esp32/restore\_state} & Receives and applies restore state \\
ESP32 & Publish \texttt{esp32/status} & Periodic status updates \\
\hline
\end{tabular}
\end{center}



\section{Motion detection via machine learning}

In the second part, the goal is to move from the threshold supported movement detection and achieve the 
operational functionalities by employing machine learning. Communication with Node-Red remains 
the same, as the machine learning classifier is executing only in ESP32 having as a result the usage
of the same topics and the same integration across ESP32-NodeRed.

\subsection{Data acquisition}

For data acquisition for each gesture, \texttt{mpu\_record.py} have been utilized in
order to send over UART a message "record" and then create samples for each of the two
classifiers respectively.
After manually we create the appropriate files to pass in the Python scripts to generate the
C functions to be used in ESP32 and use the trained classifiers.




\subsection{LEDs activation}
The system in this configuration uses the readings from the MPU9250 IMU 
and machine learning to control the LEDs. For the data collection and feature processing the IMU
continuously reads acceleration (ay) and gyroscope (gy) 
data along the Y-axis. These values are stored in an implemented circular buffer named featureBuffer (source: \texttt{CircularBuffer.h})
that maintains the 20 most recent samples(10 measurements of each Y axis of accelerometer and gyroscope)

When the buffer is full (20 samples), the features 
are processed for classification.
The raw features are first scaled using the StandardScaler parameters which were generated on the \texttt{micro2.py} Python training script
(scaler\_mean and scaler\_scale). 
The system then calculates Euclidean distances 
between the current scaled features and three reference scaled patterns 
(LED1, LED2, and Neutral) as a similarity measure.
If the distance to the Neutral pattern is below 2.0, our implemented system 
considers it a neutral position and takes no action.

Otherwise if any of the euclidean distances between the current stored sample and
the three classes(LED1 TOGGLE,LED2 TOGGLE and NEUTRAL), 
the features are passed to the SVM classifier (trained in \texttt{micro2.py}) 
which predicts whether the motion corresponds to LED1 toggle, 
LED2 toggle, or Neutral classes.

When a "LED1\_TOGGLE" prediction is made, 
and at least 900ms have passed since the last toggle (debouncing method).
The led1State boolean is flipped (true to false or false to true).
As for the PWM duty cycle, it is set to pwmLevel variable if ON, or to 0 if OFF.
Same logic as LED1, is followed for controlling "LED2\_TOGGLE" prediction.

If confidence is below 75\%, the system falls back 
into using just the distance metrics for classification.
As an addition the 900ms delay between toggles is used in order to prevent 
rapid accidental toggling that can occur inside the same running sliding window as
traversing the circular buffer of features.
Also the confidence threshold helps for filtering out uncertain predictions.

The SVM classifier used for the LEDs activation and determining actions as LED1\_TOGGLE, NEUTRAL and LED2\_TOGGLE
is getting as an input 20 features which consist of 10 samples of continuous values of (ay,gy) : 
\newline 
(\textit{ay1,gy1,ay2,gy2,...ay10,gy10}).

\begin{figure}[h!]
\centering
\begin{tikzpicture}[node distance=1.5cm and 2cm, auto]

% Input nodes
\node[draw, circle] (x1) {$x_1$};
\node[draw, circle, below=of x1] (x2) {$x_2$};
\node[draw, circle, below=of x2] (x3) {$\vdots$};
\node[draw, circle, below=of x3] (xn) {$x_20$};

% SVM box
\node[draw, rectangle, right=2cm of x2, align=center, minimum height=2cm, minimum width=2cm] (svm) {LED Classifier};

% Output nodes
\node[draw, rectangle, right=3cm of svm.north] (y1) {LED1\_TOGGLE};
\node[draw, rectangle, right=2cm of svm.center] (y2) {LED2\_TOGGLE};
\node[draw, rectangle, right=3cm of svm.south] (y3) {NEUTRAL};

% Connections
\foreach \i in {x1,x2,x3,xn}
    \draw[->] (\i) -- (svm);

\draw[->] (svm.north east) -- (y1);
\draw[->] (svm.east) -- (y2);
\draw[->] (svm.south east) -- (y3);
\end{tikzpicture}
\caption{The SVM classifier used for the LED activation actions.}
\end{figure}






\subsection{Control of PWM}

For controlling the common PWM applied in each LED in case it is "ON",
we create a second classifier which works with data acquired from 
magnetometer X axis readings. 

The SVM classifier used for determining the increase/decrease of the global used PWM value
is getting as an input 9 features which consist of 9 samples of continuous values of (mx) : 
\newline 
(\textit{mx1,mx2,...mx9}).

\begin{figure}[h!]
\centering
\begin{tikzpicture}[node distance=1.5cm and 2cm, auto]

% Input nodes
\node[draw, circle] (x1) {$x_0$};
\node[draw, circle, below=of x1] (x2) {$x_2$};
\node[draw, circle, below=of x2] (x3) {$\vdots$};
\node[draw, circle, below=of x3] (xn) {$x_9$};

% SVM box
\node[draw, rectangle, right=2cm of x2, align=center, minimum height=2cm, minimum width=2cm] (svm) {PWM Classifier};

% Output nodes
\node[draw, rectangle, right=3cm of svm.north] (y1) {INCREASE};
\node[draw, rectangle, right=3cm of svm.center] (y2) {DECREASE};
\node[draw, rectangle, right=3cm of svm.south] (y3) {NEUTRAL};

% Connections
\foreach \i in {x1,x2,x3,xn}
    \draw[->] (\i) -- (svm);
\draw[->] (svm.north east) -- (y1);
\draw[->] (svm.east) -- (y2);
\draw[->] (svm.south east) -- (y3);
\end{tikzpicture}
\caption{The SVM classifier used for the PWM actions.}
\end{figure}



	\subsubsection{Classifier's training and integration with the ESP32 platform.}
	Both of the SVM classifiers are trained in a local host with higher computational capabilities than ESP32, 
	in order to achieve classification accuracy and then transfer in the embedded system only the libraries 
	which include the weights of the trained classifier.  After generating both of the classifiers their respective library 
	files PWMClassifier.h and LEDClassifier.h are included in the source file which will be compiled and uploaded to the ESP32.
	In the source files the training for both is implemented in \texttt{micro2.py,micro3.py} respectively. Also in these files
	after training we do create one reference average sample per class which later is used for similarity comparison in the ESP32.


	\paragraph{Why euclidean distance was chosen over cosine similarity:}

	When detecting the class closest to a given point in feature space, 
	Euclidean distance can be more appropriate than cosine similarity in situations 
	where the absolute proximity of the vectors is more important than their directional alignment. 
	While cosine similarity measures how aligned two vectors are (ignoring magnitude), 
	Euclidean distance accounts for both the direction and the magnitude. 
	This becomes crucial in our situation as well as shown experimentaly from the data, 
	where cosine similarity was shown better similary to wrong gesture because the sample of 
	the wrong class was an amplification of the correct's one.
	Its like in a graphical space  when one class is slightly rotated or "hidden behind" 
	another in angle they may have different orientations but still be physically close in space. 
	In such cases, cosine similarity might consider them very different due to the angle, 
	even though they are spatially close. 
	Euclidean distance, in the other hand would correctly reflect their true closeness, 
	making it better suited for identifying the nearest class based on actual position rather than orientation.	
	For this reason in this project Euclidean distance has been utilized over the cosine similarity as a similarity measure.


	A screenshot is presented also which shows both classifiers classifying the gesture as to increase the PWM which is applied on
	the LEDs and with the LED2 toggled. We can observe the classification outputs and also the Euclidean distances for each sample
	against the reference scaled average vectors who describe each class.

	\begin{figure}[H]
			\centering
			\includegraphics[width=0.7\textwidth]{classification.png}
			\caption{classification screenshot.}
			\label{fig1:}
		\end{figure}		




	From out terminal also we can observe the values inside our esp32db database in \texttt{led\_status} measurements.c
	There is timestamp, led1 status(0-off 1-on), led2 status(same as led1) and the common pwm value.
		\begin{figure}[H]
			\centering
			\includegraphics[width=0.7\textwidth]{influx.png}
			\caption{Querying our esp32db: select * from led\_status}
			\label{fig1:}
		\end{figure}		






	\subsection{Classifier selection}
	Although the support vector machine classifier has been selected and implemented for both of the 
	classification tasks performed in the project, in the script \texttt{micro\_explore.py}
	we have tested a range of classifiers and hyperparameters in order to obtain the broader picture of what they offer and 
	how they behave on our data. Of course instead of the SVM we could have used any of these since the API calls from the generated header
	files follow the same style.
	
	As we can observe utilizing our available data, 
	SVM (using different kernel from the one we implemented and the Gaussian Naive Bayes classifiers) had 8\% 
	better F1-score than the SVM with the linear kernel that we have used.
	
		\begin{figure}[H]
			\centering
			\includegraphics[width=1\textwidth]{micro_xplore.png}
			\caption{Classifier's space exploration.}
			\label{fig1:}
		\end{figure}		







\section{Containerizing server side}


Node-Red, InfluxDB and Grafana will be run as docker containers in the last part of this project.

In the first part, the creation of the \texttt{.yml} file

{\scriptsize
\begin{verbatim}
nicko@nicko:~/implementations/esp32/mpu_assignment/docker$ cat docker-compose.yml 
version: '3'

services:
  node-red:
    image: nodered/node-red
    ports:
      - "1880:1880"
      - "18883:1883"   #different from mosquitto on host.
    volumes:
      - node-red-data:/data
    restart: unless-stopped
    depends_on:
      - influxdb

  influxdb:
    image: influxdb:1.6.4
    ports:
      - "8086:8086"
    volumes:
      - influxdb-data:/var/lib/influxdb
    environment:
      - INFLUXDB_DB=esp32db
      - INFLUXDB_ADMIN_ENABLED=true
    restart: unless-stopped

  grafana:
    image: grafana/grafana
    ports:
      - "3008:3000"      #different because of conflict on host.
    volumes:
      - grafana-data:/var/lib/grafana
    restart: unless-stopped
    depends_on:
      - influxdb

volumes:
  node-red-data:
  influxdb-data:
  grafana-data:

\end{verbatim}
}

is used in order to pass the information of what container we aim to generate
and 
{\scriptsize
\begin{verbatim}
docker-compose up -d
\end{verbatim}
}
completes this action.

To run influxdb queries and inspection of the dataset:
{\scriptsize
\begin{verbatim}
docker exec -it docker-influxdb-1 influx
\end{verbatim}
}


In Node-Red when configuring the MQTT in/outs, we need to pass the "Server" IP as Linux "see"s it on an \texttt{ifconfig} command as can be
see on the following figure.

		\begin{figure}[H]
			\centering
			\includegraphics[width=1\textwidth]{doc1.png}
			\caption{Setting server ip for MQTT nodes}
			\label{fig1:}
		\end{figure}		


For the configuration of InfluxDB nodes inside the Node-Red, on the "Server" IP, we need to pass the name of the docker container 
which in our case is \texttt{docker-influxdb-1}.

		\begin{figure}[H]
			\centering
			\includegraphics[width=0.8\textwidth]{doc2.png}
			\caption{Setting server ip for InfluxDB nodes.}
			\label{fig1:}
		\end{figure}		

For the password previously we assigned via command line on \texttt{influx-cli}:

{\scriptsize
\begin{verbatim}
CREATE USER "myuser" WITH PASSWORD 'mypassword'
GRANT ALL ON "esp32db" TO "myuser"
\end{verbatim}
}
By completing those configurations we have the same functionality as before by running the two server services 
in separate Docker containers, without the need to modify anything on the source code of the ESP32.

\subsection{Current MQTT communication architecture}

The ESP32 device connects to the local Wi-Fi network using the 
credentials \texttt{ssid} and \texttt{password}. 
It establishes an MQTT client connection to the Mosquitto broker running on the host machine at its IP address and port \texttt{1883}. 
Meanwhile, the Node-RED service is containerized within the Docker 
and also connects to the same Mosquitto broker on the host, 
using the Docker host IP address to communicate with the broker as shown in the upcoming figure.

All MQTT messages published by the ESP32 are received by the Mosquitto broker 
and then routed to Node-RED flows subscribed to the respective topics. 
This setup enables the communication between the hardware and the Node-RED 
environment through a shared MQTT broker.

\begin{tikzpicture}[
  device/.style={rectangle, draw, rounded corners, minimum width=2cm, minimum height=0.7cm, fill=blue!20, font=\footnotesize},
  broker/.style={ellipse, draw, fill=green!20, minimum width=2.5cm, minimum height=0.7cm, font=\footnotesize},
  arrow/.style={-{Stealth[length=2mm]}, thick},
  node distance=2cm and 3cm
  ]

  % Nodes
  \node[device] (esp) {ESP32 (Wi-Fi)};
  \node[broker, right=3cm of esp] (broker) {Mosquitto Broker \\ (Host IP::1883)};
  \node[device, below=1.5cm of broker] (nodered) {Node-RED \\ (Docker container)};
  
  % Connections
  \draw[arrow] (esp) -- node[above, font=\footnotesize] {MQTT Pub/Sub} (broker);
  \draw[arrow] (broker) -- node[right, font=\footnotesize] {MQTT Pub/Sub} (nodered);

  % Network labels
  \node[above=0.4cm of esp, font=\footnotesize] {Local Wi-Fi Network};
  \node[right=0.1cm of nodered, font=\footnotesize] {Docker Network \\ };

\end{tikzpicture}

\subsection{Grafana visualization}

To access Grafana, we navigate to \texttt{http://localhost:3008/} since we have changed the 3000 port to 3008 due to machine port conflict.
In the next step, connection to InfluxDB is performed by setting the appropiate Server IP and database for reading the data to be visualized.

		\begin{figure}[H]
			\centering
			\includegraphics[width=1\textwidth]{graf1.png}
			\caption{Grafana: configuring the InfluxDB data source.}
			\label{fig1:}
		\end{figure}		


After creating a new Dashboard and creating 2 queries to fetch our data, we visualize the LED1 and LED2 status and in a separate plot
the PWM status with an auto refresh of 5 seconds. There is flexibility to develop any kind of visualization we like based on the query we need.
We observe ours in the following figure.

		\begin{figure}[H]
			\centering
			\includegraphics[width=1\textwidth]{graf2.png}
			\caption{Grafana: visualization.}
			\label{fig1:}
		\end{figure}		


	Also we can observe the visualization by accesing Grafana's dashboard from a mobile phone connected in the same network by navigating
	on \texttt{IP-of host machine hosting server:port}.


		\begin{figure}[H]
			\centering
			\includegraphics[width=0.5\textwidth]{graf3.jpeg}
			\caption{access from another machine(mobile) on the same net.}
			\label{fig1:}
		\end{figure}		




\end{document}

